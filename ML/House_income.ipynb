{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taube0/MVP---Income-prediction/blob/main/House_income.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1º - Carga do Dataset com URL\n"
      ],
      "metadata": {
        "id": "uYyMh3ZdWq9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iu9vJY6mNabf",
        "outputId": "eaaa26a2-1ac4-4282-cfa2-d9ad3dfe4159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.combine import SMOTEENN\n",
        "import joblib\n",
        "\n",
        "# Carregando o dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "           'hours-per-week', 'native-country', 'income']\n",
        "data = pd.read_csv(url, header=None, names=columns, na_values=' ?', skipinitialspace=True)\n",
        "\n",
        "# Convertendo a coluna alvo ('income') para valores binários\n",
        "data['income'] = data['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
        "\n",
        "# Separando variáveis independentes e alvo\n",
        "X = data.drop('income', axis=1)\n",
        "y = data['income']\n",
        "\n",
        "# Identificando colunas numéricas e categóricas\n",
        "num_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "cat_features = ['workclass', 'education', 'marital-status', 'occupation',\n",
        "                'relationship', 'race', 'sex', 'native-country']\n",
        "\n",
        "# Definindo pré-processamento para colunas numéricas e categóricas\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combinando transformadores\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_features),\n",
        "        ('cat', categorical_transformer, cat_features)\n",
        "    ])\n",
        "\n",
        "# Dividindo o dataset em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Pré-processando os dados\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Aplicando SMOTEENN para balancear as classes no conjunto de treino\n",
        "smoteenn = SMOTEENN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train_preprocessed, y_train)\n",
        "\n",
        "# Salvando as variáveis em um arquivo .pkl\n",
        "joblib.dump((X_train_resampled, X_test_preprocessed, y_train_resampled, y_test, preprocessor), 'data.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2º - Criação e avaliação de modelos\n"
      ],
      "metadata": {
        "id": "6qhSZx13XD0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Carregando dados pré-processados do arquivo .pkl\n",
        "X_train_resampled, X_test_preprocessed, y_train_resampled, y_test, preprocessor = joblib.load('data.pkl')\n",
        "\n",
        "# Verificando as colunas do dataset\n",
        "print(\"Colunas do X_train_resampled:\", X_train_resampled.shape)\n",
        "print(\"Colunas do X_test_preprocessed:\", X_test_preprocessed.shape)\n",
        "\n",
        "# Criando um pipeline com apenas o modelo, já que os dados estão pré-processados\n",
        "pipeline = Pipeline([\n",
        "    ('model', None)  # O modelo será definido no GridSearchCV\n",
        "])\n",
        "\n",
        "# Dicionário de modelos e parâmetros para GridSearch\n",
        "models = {\n",
        "    'KNN': (KNeighborsClassifier(), {'model__n_neighbors': [3, 5, 7]}),\n",
        "    'Decision Tree': (DecisionTreeClassifier(), {'model__max_depth': [3, 5, 7]}),\n",
        "    'Naive Bayes': (GaussianNB(), {}),\n",
        "    'SVM': (SVC(probability=True, class_weight='balanced'), {'model__C': [0.1, 1, 10], 'model__gamma': [0.1, 0.01]})\n",
        "}\n",
        "\n",
        "# Variáveis para rastrear o melhor modelo\n",
        "best_f1_score = -1\n",
        "best_model = None\n",
        "best_model_name = ''\n",
        "\n",
        "# Realizando GridSearch para cada modelo\n",
        "for model_name, (model, params) in models.items():\n",
        "    print(f\"Treinando o modelo: {model_name}\")\n",
        "\n",
        "    # Verifica se o modelo exige dados densos e faz a conversão, se necessário\n",
        "    if model_name in ['Naive Bayes', 'SVM']:\n",
        "        # Convertendo dados esparsos para densos\n",
        "        X_train_resampled_dense = X_train_resampled.toarray()\n",
        "        X_test_preprocessed_dense = X_test_preprocessed.toarray()\n",
        "        X_train_to_use = X_train_resampled_dense\n",
        "        X_test_to_use = X_test_preprocessed_dense\n",
        "    else:\n",
        "        X_train_to_use = X_train_resampled\n",
        "        X_test_to_use = X_test_preprocessed\n",
        "\n",
        "    # Definindo o modelo no pipeline\n",
        "    pipeline.set_params(model=model)\n",
        "\n",
        "    # Configurando o GridSearchCV\n",
        "    grid_search = GridSearchCV(pipeline, param_grid=params, cv=5, scoring='f1', error_score='raise')\n",
        "\n",
        "    try:\n",
        "        # Treinamento do modelo com GridSearch\n",
        "        grid_search.fit(X_train_to_use, y_train_resampled)\n",
        "\n",
        "        # Salvando o melhor modelo encontrado\n",
        "        best_model_filename = f'best_model_{model_name.lower().replace(\" \", \"_\")}.pkl'\n",
        "        joblib.dump(grid_search.best_estimator_, best_model_filename)\n",
        "        print(f\"Modelo {model_name} salvo em {best_model_filename}\")\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        y_pred = grid_search.predict(X_test_to_use)\n",
        "        f1_score = grid_search.best_score_\n",
        "        print(f\"Modelo: {model_name}, Melhor F1: {f1_score}\")\n",
        "\n",
        "        # Verificando se este é o melhor modelo até agora\n",
        "        if f1_score > best_f1_score:\n",
        "            best_f1_score = f1_score\n",
        "            best_model = grid_search.best_estimator_\n",
        "            best_model_name = model_name\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Erro ao treinar o modelo {model_name}: {e}\")\n",
        "\n",
        "# Salvando o modelo com a melhor F1-Score como 'best_model.pkl'\n",
        "if best_model:\n",
        "    joblib.dump(best_model, 'best_model.pkl')\n",
        "    print(f\"Melhor modelo ({best_model_name}) salvo como 'best_model.pkl' com F1-Score: {best_f1_score}\")\n",
        "else:\n",
        "    print(\"Nenhum modelo foi treinado com sucesso.\")"
      ],
      "metadata": {
        "id": "qe46y89ONcG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3b02b6-1540-4cea-af0f-4b9f0876e8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colunas do X_train_resampled: (29767, 108)\n",
            "Colunas do X_test_preprocessed: (6513, 108)\n",
            "Treinando o modelo: KNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3º - Exportação do melhor modelo"
      ],
      "metadata": {
        "id": "e2u7JV1VXVKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "# Carregando o melhor modelo gerado no treinamento\n",
        "best_model = joblib.load('best_model.pkl')\n",
        "\n",
        "# Carregando as variáveis do arquivo .pkl\n",
        "X_train, X_test, y_train, y_test, preprocessor = joblib.load('data.pkl')\n",
        "\n",
        "# Avaliando o modelo no conjunto de teste\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(f\"Classification report para o melhor modelo:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "id": "RltwoN0aNxgD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
